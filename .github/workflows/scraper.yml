name: Scraper Goyabu + AniList

on:
  workflow_dispatch:   # permite rodar manualmente
  schedule:
    - cron: "0 2 * * *"  # diário às 2h UTC

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checa o código
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true  # permite push automático

      # 2️⃣ Configura Python
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      # 3️⃣ Instala dependências
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install googletrans==4.0.0-rc1 requests beautifulsoup4 deep-translator google-genai

      # 4️⃣ Garante que a pasta e arquivo existam
      - name: Prepare output
        run: |
          mkdir -p scraper/output
          touch scraper/output/animes.json

      # 5️⃣ Roda o scraper
      - name: Run scraper
        run: |
          python main.py
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}  # chave da Gemini

      # 6️⃣ Commit e push do JSON gerado
      - name: Commit output
        run: |
          if [ -f scraper/output/animes.json ]; then
            git config --global user.name "github-actions"
            git config --global user.email "actions@github.com"
            git add scraper/output/animes.json
            git commit -m "Atualizar scraper output [skip ci]" || echo "Sem alterações para commit"
            git push
          else
            echo "Arquivo scraper/output/animes.json não existe, pulando commit"